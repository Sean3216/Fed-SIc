{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894bf50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.model import load_model\n",
    "from utils.functionality import train, test, create_datasets\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "raw",
   "id": "833e827f",
   "metadata": {},
   "source": [
    "train(model, trainloader, epochs, device, valloader)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5c13588",
   "metadata": {},
   "source": [
    "assume theres a blockchain:\n",
    "clients = {'cid1':{'m2':90, 'm3':40}, \n",
    "           'cid2':{'m1':40,'m3':25}, \n",
    "           'cid3':{'m1':65,'m2':86}}\n",
    "translated into this:\n",
    "clients = {'cid1':{2:90, 3:40}, \n",
    "           'cid2':{1:40,3:25}, \n",
    "           'cid3':{1:65,2:86}}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "81f4ebde",
   "metadata": {},
   "source": [
    "the clients send only the model parameter first, and then server send the weights of all clients to each client.\n",
    "And then client sends back only the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efacbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server():\n",
    "    def __init__(self,clients: dict):\n",
    "        self.globalmodel = load_model('Net')\n",
    "        #for clients, there should be a nested dictionary\n",
    "        self.clients = pd.DataFrame(clients)\n",
    "        self.candidatesavg = {i+1: sum(self.clients.loc[i+1])/len(self.clients) for i in range(len(self.clients))}\n",
    "        \n",
    "    #### Vanilla FL Function    \n",
    "    def aggregate(self,modelparams: list):\n",
    "        params = [model.parameters() for model in modelparams] #obtain model params\n",
    "        sumparams = [sum(param) for param in zip(*params)] #sum the model\n",
    "        avgparams = [param/len(params) for param in sumparams] #average the model\n",
    "        for param, avgparams in zip(self.globalmodel.parameters(), avgparams):\n",
    "            param.data.copy_(avgparams.data)\n",
    "            \n",
    "    def sendparams(self,clientmodel):\n",
    "        clientmodel.load_state_dict(self.globalmodel.state_dict())\n",
    "        return clientmodel\n",
    "    \n",
    "    #### Proposed Idea Functions\n",
    "    def choose_eval_cand(evalnum = 2, candidatesavg: dict, rounds):\n",
    "        evaluator = []\n",
    "        #### Select evaluators and early candidates\n",
    "        for i in range(evalnum):\n",
    "            tobeeval = max(candidatesavg,keys = candidatesavg.get)\n",
    "            candidatesavg.pop(tobeeval,None)\n",
    "            evaluator.append(tobeeval)\n",
    "        #then the rest of the keys left becomes the candidates\n",
    "        earlycandidates = []\n",
    "        for key in candidatesavg.keys():\n",
    "            earlycandidates.append(key)\n",
    "            \n",
    "        #### Assign probability to candidates\n",
    "        candidatesprob = {}\n",
    "        if rounds == 0:\n",
    "            #client i model accuracy / all client model accuracy\n",
    "            for i in earlycandidates:\n",
    "                candidatesprob[i+1] = candidatesavg[i+1] / sum(candidatesavg.values())\n",
    "        else:\n",
    "            #how to simulate bid price?\n",
    "        \n",
    "        #### Select final candidates based on probability\n",
    "        finalcandidates = []\n",
    "        for i in candidatesprob.keys():\n",
    "            if candidatesprob[i] > np.random.rand():\n",
    "                finalcandidates.append(i)\n",
    "            else:\n",
    "                continue\n",
    "        return evaluator, finalcandidates \n",
    "    \n",
    "    def getclientinfo():\n",
    "        pass\n",
    "        return clients, modelparameters\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab79bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(numrounds):  \n",
    "    #### initiate data\n",
    "    local, test = create_datasets('./data','CIFAR10',num_clients=10, num_shards=200, iid=False, print_count = True)\n",
    "    \n",
    "    #### initiate federated learning rounds\n",
    "    rounds = 0\n",
    "    for i in range(numrounds):\n",
    "        #client = Client()\n",
    "        #parameters = client.parameter\n",
    "        #identity = client.id\n",
    "        #scores = client.scores\n",
    "        \n",
    "        #### Obtain weights\n",
    "        client_params = {}\n",
    "        for i in clients: #for models in clients\n",
    "            client_params[client.id] = client.parameter\n",
    "            \n",
    "        #### Send weights\n",
    "        for i in client_params: #for client id in saved client_id\n",
    "            \n",
    "        #### client send score back to server\n",
    "        savedscore = {}\n",
    "        #clients = {'cid1':{2:90, 3:40}, \n",
    "           #'cid2':{1:40,3:25}, \n",
    "           #'cid3':{1:65,2:86}}\n",
    "        for i in clients: #for client id in saved client_id\n",
    "            savedscore[i] = {}\n",
    "            \n",
    "        #clients, modelparams = getclientinfo() ###make this into 2 functions, one to get the score only, one to get the parameters\n",
    "        \n",
    "        #### Server helps choose candidate\n",
    "        server = Server(clients, modelparams, evalnum, testdata)\n",
    "        evaluator, finalcandidates = choose_eval_candidates(evalnum = 2, server.candidatesavg)\n",
    "        #server sends weights of final candidates to evaluator. Evaluator test. Evaluator choose candidates who passed (criteria?)\n",
    "        #evaluator sends clients who's accepted and declined\n",
    "        #server only use clients who's accepted to be aggregated with the evaluator model\n",
    "        #### Server aggregates      \n",
    "        #what does the modelparams looks like? does it have client index? is it a list or an index?\n",
    "        server.aggregate(modelparams) #aggregate\n",
    "        \n",
    "        loss, accuracy = test(server.globalmodel, test, device = \"gpu\")\n",
    "        print(\"Round 1 metrics:\")\n",
    "        print(\"Loss = {}\".format(loss))\n",
    "        print(\"Accuracy = {}\".format(accuracy))\n",
    "        \n",
    "        server.sendparams(clientmodel) #sending parameters\n",
    "        \n",
    "        #### Calculate contributions of clients \n",
    "        #after contributions is calculated, select next evaluator by contribution value\n",
    "        #### give reputations \n",
    "        rounds += 1\n",
    "        \n",
    "        #### Begin round 2 by selecting candidates. Selection is different, be careful\n",
    "        #repeat\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b03c5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "520610bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clientscores = {\"eid0\":{1:33, 2:23},\"eid1\":{0:46,2:70},\"eid2\":{0:90,1:22}}\n",
    "\n",
    "def get_cand_avg(clientsscores):\n",
    "        print(\"This is the client scores\")\n",
    "        print(clientsscores)\n",
    "        clients = pd.DataFrame(clientsscores).fillna(0)\n",
    "        #print(\"This is the Dataframe consist of model performance\")\n",
    "        display(clients)\n",
    "        candidatesavg = {i: sum(clients.loc[i])/(len(clients)-1) for i in range(len(clients))}\n",
    "        print(\"this is candidates avg!: {}\".format(candidatesavg))\n",
    "        return candidatesavg"
   ]
  },
  {
   "cell_type": "raw",
   "id": "802f059c",
   "metadata": {},
   "source": [
    "def clientseval(self, clientconfig):\n",
    "        clientscores = {}\n",
    "        for report in self.params.keys():\n",
    "            reportclient = Client(clientconfig[report])\n",
    "            reportclient.model = MnistModel()\n",
    "            clientscores[report] = {}\n",
    "            for cand in self.params.keys():\n",
    "                if report != cand:\n",
    "                    reportclient.model.load_state_dict(self.params[cand])\n",
    "                    clientscores[report][cand] = reportclient.test()['acc']\n",
    "                else:\n",
    "                    continue\n",
    "        return clientscores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c45d7f",
   "metadata": {},
   "source": [
    "First key is evaluator, second key is the client's performance on that evaluator data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3c00115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eid0': {1: 33, 2: 23}, 'eid1': {0: 46, 2: 70}, 'eid2': {0: 90, 1: 22}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clientscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cd6c12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the client scores\n",
      "{'eid0': {1: 33, 2: 23}, 'eid1': {0: 46, 2: 70}, 'eid2': {0: 90, 1: 22}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid0</th>\n",
       "      <th>eid1</th>\n",
       "      <th>eid2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eid0  eid1  eid2\n",
       "1  33.0   0.0  22.0\n",
       "2  23.0  70.0   0.0\n",
       "0   0.0  46.0  90.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is candidates avg!: {0: 68.0, 1: 27.5, 2: 46.5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 68.0, 1: 27.5, 2: 46.5}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cand_avg(clientscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd7b60d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
